{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ea804cfde024182b86538a174e49c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a86b7e32d4d04ff5a34a4eeaa520dbbb",
              "IPY_MODEL_34625118745844d598fe470c78ccd961",
              "IPY_MODEL_a3acf2d9166a44b3b15d525b5ee145ab"
            ],
            "layout": "IPY_MODEL_c244524194ba49f887f7e7788cb213a1"
          }
        },
        "a86b7e32d4d04ff5a34a4eeaa520dbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41900aae05c24219b5c5535fd80ca814",
            "placeholder": "​",
            "style": "IPY_MODEL_8e342bd1383a421883313c8850a3e10a",
            "value": "Epochs:   0%"
          }
        },
        "34625118745844d598fe470c78ccd961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_693c8fb85a2a4f388f777fe4a2118c67",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96086e93a44f42baa8a54fb3b8f490d7",
            "value": 0
          }
        },
        "a3acf2d9166a44b3b15d525b5ee145ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce917df208e84d64a4fa1c6c60529176",
            "placeholder": "​",
            "style": "IPY_MODEL_7788e44417f5429bba684ed32c48b444",
            "value": " 0/4 [00:00&lt;?, ?it/s]"
          }
        },
        "c244524194ba49f887f7e7788cb213a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41900aae05c24219b5c5535fd80ca814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e342bd1383a421883313c8850a3e10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "693c8fb85a2a4f388f777fe4a2118c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96086e93a44f42baa8a54fb3b8f490d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce917df208e84d64a4fa1c6c60529176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7788e44417f5429bba684ed32c48b444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88d2c1471320434e946103ab794deae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b552c9d3e4ed4c828c7caa28458df519",
              "IPY_MODEL_b5bd6ec136ff430793c370648abe184b",
              "IPY_MODEL_8e0525d9b24848ef97412a7bbe48e4b2"
            ],
            "layout": "IPY_MODEL_84d5eaff506d4f6381d2a8ecb204d25e"
          }
        },
        "b552c9d3e4ed4c828c7caa28458df519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d539adecd246f79bdb10dee35491de",
            "placeholder": "​",
            "style": "IPY_MODEL_a61da37cea494d8f87e5e902b7770200",
            "value": "Training Batches:   0%"
          }
        },
        "b5bd6ec136ff430793c370648abe184b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a0a39cf6e9d4f9685e946c95de3b72b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4634288a4b294f1f8d97421ffae3bd44",
            "value": 0
          }
        },
        "8e0525d9b24848ef97412a7bbe48e4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aceb8ffee004bf399e8c86e55ab68a3",
            "placeholder": "​",
            "style": "IPY_MODEL_10b36aa4192f489c8ae9d19390daf8fe",
            "value": " 0/3 [00:00&lt;?, ?it/s]"
          }
        },
        "84d5eaff506d4f6381d2a8ecb204d25e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d539adecd246f79bdb10dee35491de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a61da37cea494d8f87e5e902b7770200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a0a39cf6e9d4f9685e946c95de3b72b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4634288a4b294f1f8d97421ffae3bd44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3aceb8ffee004bf399e8c86e55ab68a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b36aa4192f489c8ae9d19390daf8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is for kaggle competition"
      ],
      "metadata": {
        "id": "ll-B2gfPHc75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tons and tons of imports!\n",
        "from collections import Counter, namedtuple\n",
        "from itertools import chain\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from typing import List, Tuple, Dict, Set, Union\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, TensorDataset\n",
        "import torch.nn.utils\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plot"
      ],
      "metadata": {
        "id": "FJU9aA6rJ_ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "Hkn9JgTYH9IK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef72c42-7b18-400c-c64c-893bd8c6e016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data**"
      ],
      "metadata": {
        "id": "unDkKa--dGWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LF_train  = pd.read_csv('drive/MyDrive/Colab Notebooks/kaggle_ml/data/LF_train.csv')\n",
        "LF_test = pd.read_csv('drive/MyDrive/Colab Notebooks/kaggle_ml/data/LF_test.csv')\n",
        "LH_train = pd.read_csv('drive/MyDrive/Colab Notebooks/kaggle_ml/data/LH_train.csv')\n",
        "LH_test = pd.read_csv('drive/MyDrive/Colab Notebooks/kaggle_ml/data/LH_test.csv')\n",
        "RF_train  = pd.read_csv('drive/MyDrive/Colab Notebooks/kaggle_ml/data/RF_train.csv')\n",
        "RF_test = pd.read_csv('drive/MyDrive/Colab Notebooks/kaggle_ml/data/RF_test.csv')\n",
        "RH_train = pd.read_csv('drive/MyDrive/Colab Notebooks/kaggle_ml/data/RH_train.csv')\n",
        "RH_test = pd.read_csv('drive/MyDrive/Colab Notebooks/kaggle_ml/data/RH_test.csv')"
      ],
      "metadata": {
        "id": "mQWFCYM3Lw-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date Processing**"
      ],
      "metadata": {
        "id": "eSmF2VD2UCYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### turn literals into numericals\n",
        "LF_train = LF_train.drop(columns=['dob', 'gait', 'Gait'])\n",
        "LF_train['forceplate_date'] = LF_train['forceplate_date'].str.replace(\"-\",\"\").astype(int)\n",
        "\n",
        "### nan value\n",
        "LF_train = LF_train.fillna(0)\n",
        "LF_train = LF_train.replace('Not able to trot', 0)\n",
        "LF_train = LF_train.replace('Not able to walk', 0)\n",
        "LF_train = LF_train.replace('no data', 0)\n",
        "LF_train['Speed'] = LF_train['Speed'].astype(float)\n",
        "\n",
        "for col in LF_train.columns:\n",
        "    if 'V' in col or 'Speed' in col :\n",
        "        LF_train[col] = LF_train[col].replace(0, LF_train[col].mean())\n",
        "\n",
        "### sort by id\n",
        "LF_train = LF_train.sort_values(by=['id'])\n",
        "\n",
        "### extract the golden standard\n",
        "LF_train_labels = LF_train['LF']\n",
        "LF_train_data = LF_train.drop(\"LF\", axis='columns')\n",
        "\n",
        "### turn the data frames into numpy data type\n",
        "LF_train_labels = LF_train_labels.to_numpy()\n",
        "LF_train_data = LF_train_data.to_numpy()\n",
        "\n",
        "### split the data for training and evaluation - random_state is a seed\n",
        "XLF_train, XLF_val, yLF_train, yLF_val = train_test_split(LF_train_data, LF_train_labels, random_state = 1)\n",
        "\n",
        "### (optional)perform PCA and get rid of columns with low variance\n",
        "### (optional)get rid of the id columns to reduce 'noise'\n",
        "print(\"XLF_train shape: \", XLF_train.shape)\n",
        "print(\"yLF_train shape: \", yLF_train.shape)"
      ],
      "metadata": {
        "id": "AhGRrh2L5PNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d64b0f5-7725-46b8-84ef-000df5cfe2e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLF_train shape:  (82, 367)\n",
            "yLF_train shape:  (82,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### convert the numpy data types into torch tensors that we want to use in the neural networks\n",
        "XLF_train = np.vstack(XLF_train).astype(float)\n",
        "yLF_train = np.vstack(yLF_train).astype(float)\n",
        "XLF_val = np.vstack(XLF_val).astype(float)\n",
        "yLF_val = np.vstack(yLF_val).astype(float)\n",
        "\n",
        "XLF_train = torch.from_numpy(XLF_train).to(torch.float32)\n",
        "yLF_train = torch.from_numpy(yLF_train).to(torch.float32)\n",
        "XLF_val = torch.from_numpy(XLF_val).to(torch.float32)\n",
        "yLF_val = torch.from_numpy(yLF_val).to(torch.float32)"
      ],
      "metadata": {
        "id": "jB8MLAN4d-Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "XLF_train_dset = TensorDataset(XLF_train, yLF_train)\n",
        "XLF_train_dloader = DataLoader(XLF_train_dset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "XLF_val_dset = TensorDataset(XLF_val, yLF_val)\n",
        "XLF_val_dloader = DataLoader(XLF_val_dset, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "7JKT8A3alC_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### sanity check for data frame, not python array - whether there's still nan values\n",
        "# LF_train.isnull().any().any()"
      ],
      "metadata": {
        "id": "rTsvyzfpU1vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # split by walk / trot\n",
        "# trot_list = []\n",
        "# name_list = []\n",
        "# for col in LF_train.columns:\n",
        "#     if 'trot' in col:\n",
        "#         trot_list.append(col)\n",
        "\n",
        "#         new_name = col.split('_trot')\n",
        "#         name_list.append(new_name[0])\n",
        "\n",
        "# LF_train_trot = pd.DataFrame(LF_train, columns = trot_list)\n",
        "# LF_train_trot.columns = name_list\n",
        "\n",
        "# both = ['id', 'gender', 'weight', 'forceplate_date', 'speed', 'age', 'Speed', 'LF']\n",
        "# LF_train_both = pd.DataFrame(LF_train, columns = both)\n",
        "\n",
        "# # add binary col is_trot\n",
        "# LF_train_trot = LF_train_both.join(LF_train_trot)\n",
        "# LF_train_trot['is_trot'] = 1\n",
        "\n",
        "# LF_train_walk = LF_train.drop(columns=trot_list)\n",
        "# LF_train_walk['is_trot'] = 0\n",
        "\n",
        "# # concat walk and trot\n",
        "# LF_train = pd.concat([LF_train_walk, LF_train_trot])"
      ],
      "metadata": {
        "id": "TJcwHuktTiaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FFNN construct**"
      ],
      "metadata": {
        "id": "exUXE_T4c4DV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0PjZPW60Y5W"
      },
      "outputs": [],
      "source": [
        "# Lambda to switch to GPU if available\n",
        "get_device = lambda : \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = get_device()\n",
        "# Setting seed ***DO NOT MODIFY***\n",
        "torch.manual_seed(123)\n",
        "\n",
        "################################################################################\n",
        "#########################             ADDED             ########################\n",
        "################################################################################\n",
        "def weight_init(m):\n",
        "\tif isinstance(m, nn.Linear):\n",
        "\t\tnn.init.xavier_uniform_(m.weight)\n",
        "\t\tnn.init.constant_(m.bias, 0.)\n",
        "\n",
        "# Consult the PyTorch documentation for information on the functions used below:\n",
        "# https://pytorch.org/docs/stable/torch.html\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "\tdef __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\t\tsuper(FFNN, self).__init__()\n",
        "\t\t############################################################################\n",
        "\t\t#########################             ADDED             ####################\n",
        "\t\t############################################################################\n",
        "\t\tself.loss_class_weights = torch.tensor([1, 1], \n",
        "\t\t                                       dtype=torch.float)\n",
        "\t\t# self.embedding = nn.Embedding(vocab_size, embedding_dim, max_norm=True)\n",
        "\t  ### TODO : initialize your model with the necessary layers and functions ###\n",
        "\t\t\n",
        "\n",
        "\t\t### Here are pytorch docs which you may find useful:\n",
        "\t\t### Linear layer:\n",
        "\t\t###\t\thttps://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "\t\tself.W = nn.Linear(input_dim, hidden_dim)\n",
        "\t\tself.W_x = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\t\t### ReLU: \n",
        "\t\t###\t\thttps://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
        "\t\tself.relu = nn.ReLU()           \n",
        "\t\t### LogSoftmax:\n",
        "\t\t###\t\thttps://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html\n",
        "\t\tself.softmax = nn.LogSoftmax(dim = 1)\n",
        "\t\t### NLLoss:\n",
        "\t\t###\t\thttps://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html\n",
        "\t\tself.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\t##############################################################################\n",
        "\t#########################           CHANGED             ######################\n",
        "\t##############################################################################\n",
        "\tdef compute_Loss(self, predicted_vector, gold_label):\n",
        "\t\t## cross entropy documentation\n",
        "\t\treturn self.loss(predicted_vector, gold_label)\n",
        "\n",
        "\tdef forward(self, input_vector):\n",
        "\t\t############################################################################\n",
        "\t\t#########################             ADDED             ####################\n",
        "\t\t############################################################################\n",
        "\t\t # input_vector=(batch_size, max_len)\n",
        "\t\toriginal_shape = input_vector.shape\n",
        "\n",
        "\t\t# input_vector = input_vector.reshape(-1)\n",
        "\n",
        "\t\t\n",
        "\t\t# The z_i are just there to record intermediary computations for your clarity\n",
        "\t\t# embeddings = self.embedding(input_vector) \n",
        "\t\tz1 = self.W(input_vector)\n",
        "\t\t\n",
        "\t\t# correction 1: No activation on z1; no linear layer for z2; mistakingly softmax z1\n",
        "\t\tz1_relu = self.relu(z1)\n",
        "\t\tz2 = self.W_x(z1_relu)\n",
        "\t\tpredicted_vector = self.softmax(z2)\n",
        "\t\t# predicted_vector = self.softmax(z1)\n",
        "\t\t# correction 1 end\n",
        "\t\t\n",
        "\t\t# predicted_vector=(batch_size, row length, output_dim)\n",
        "\t\tpredicted_vector = predicted_vector.reshape((original_shape[0],\n",
        "                                                 original_shape[1], -1))\n",
        "\n",
        "\t\treturn predicted_vector\n",
        "\n",
        "\tdef load_model(self, save_path):\n",
        "\t\tself.load_state_dict(torch.load(save_path))\n",
        "\n",
        "\tdef save_model(self, save_path):\n",
        "\t\ttorch.save(self.state_dict(), save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FFNN training**"
      ],
      "metadata": {
        "id": "VWwIlNyLdMPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting seed ***DO NOT MODIFY***\n",
        "torch.manual_seed(123)\n",
        "################################################################################\n",
        "#########################             CHANGED             ######################\n",
        "################################################################################\n",
        "def train_epoch(model, train_loader, optimizer):\n",
        "  model.train()\n",
        "  total = 0\n",
        "  batch = 0\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  for (input_batch, expected_out) in tqdm(train_loader, leave=False, desc=\"Training Batches\"):\n",
        "    optimizer.zero_grad()\n",
        "    # correction 2: batch = 1 is incorrect\n",
        "    batch += 1\n",
        "    flattened_expected_out = expected_out.reshape(-1).to(device)\n",
        "    # flattened_batch_mask = batch_mask.reshape(-1).to(device)\n",
        "    output = model(input_batch.to(get_device())).to(get_device())\n",
        "    flattened_output = output.reshape(-1, output.shape[-1])\n",
        "    loss = model.compute_Loss(flattened_output, flattened_expected_out)\n",
        "    total += torch.size(flattened_expected_out)[0]\n",
        "    _, predicted = torch.max(output, -1)\n",
        "    flattened_predicted = predicted.reshape(-1)\n",
        "    # correction 3: We think correct should increase instead of decrease\n",
        "    # correct -= (flattened_expected_out[flattened_batch_mask].to(\"cpu\") == flattened_predicted[flattened_batch_mask].to(\"cpu\")).cpu().numpy().sum()\n",
        "    correct += (flattened_expected_out.to(\"cpu\") == flattened_predicted.to(\"cpu\")).cpu().numpy().sum()\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    # correction 4: SGD wasn't performed\n",
        "    optimizer.step()\n",
        "    \n",
        "  print(\"Loss: \" + str(total_loss/batch))\n",
        "  print(\"Training Accuracy: \" + str(correct/total))\n",
        "  return total_loss/batch"
      ],
      "metadata": {
        "id": "twunIbprc1ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting seed ***DO NOT MODIFY***\n",
        "torch.manual_seed(123)\n",
        "\n",
        "def evaluation(model, val_loader, optimizer):\n",
        "  model.eval()\n",
        "  loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for (input_batch, expected_out) in tqdm(val_loader, leave=False, desc=\"Validation Batches\"):\n",
        "    output = model.forward(input_batch.to(get_device())).to(get_device())\n",
        "    total += output.size()[1]\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    correct += (expected_out.to(\"cpu\") == predicted.to(\"cpu\")).cpu().numpy().sum()\n",
        "    loss += model.compute_Loss(output, expected_out.to(get_device()))\n",
        "  loss /= len(val_loader)\n",
        "  print(\"Validation Loss: \" + str(loss.item()))\n",
        "  print(\"Validation Accuracy: \" + str(correct/total))\n",
        "  print()\n",
        "  return loss.item()"
      ],
      "metadata": {
        "id": "ZA1zCWZV1PnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting seed ***DO NOT MODIFY***\n",
        "torch.manual_seed(123)\n",
        "def train_and_evaluate(number_of_epochs, model, train_loader, val_loader, min_loss=0, lr=.001):\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=.01)\n",
        "  loss_values = [[],[]]\n",
        "  for epoch in trange(number_of_epochs, desc=\"Epochs\"):\n",
        "    cur_loss = train_epoch(model, train_loader, optimizer)\n",
        "    loss_values[0].append(cur_loss)\n",
        "    cur_loss_val = evaluation(model, val_loader, optimizer)\n",
        "    loss_values[1].append(cur_loss_val)\n",
        "    if cur_loss <= min_loss: return loss_values\n",
        "  return loss_values"
      ],
      "metadata": {
        "id": "gSsHRUXReLPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCa0WxPl1Wbl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "7ea804cfde024182b86538a174e49c16",
            "a86b7e32d4d04ff5a34a4eeaa520dbbb",
            "34625118745844d598fe470c78ccd961",
            "a3acf2d9166a44b3b15d525b5ee145ab",
            "c244524194ba49f887f7e7788cb213a1",
            "41900aae05c24219b5c5535fd80ca814",
            "8e342bd1383a421883313c8850a3e10a",
            "693c8fb85a2a4f388f777fe4a2118c67",
            "96086e93a44f42baa8a54fb3b8f490d7",
            "ce917df208e84d64a4fa1c6c60529176",
            "7788e44417f5429bba684ed32c48b444",
            "88d2c1471320434e946103ab794deae1",
            "b552c9d3e4ed4c828c7caa28458df519",
            "b5bd6ec136ff430793c370648abe184b",
            "8e0525d9b24848ef97412a7bbe48e4b2",
            "84d5eaff506d4f6381d2a8ecb204d25e",
            "99d539adecd246f79bdb10dee35491de",
            "a61da37cea494d8f87e5e902b7770200",
            "3a0a39cf6e9d4f9685e946c95de3b72b",
            "4634288a4b294f1f8d97421ffae3bd44",
            "3aceb8ffee004bf399e8c86e55ab68a3",
            "10b36aa4192f489c8ae9d19390daf8fe"
          ]
        },
        "outputId": "07a1d6a5-43bf-4a9b-e9a1-5cdfa0106e89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ea804cfde024182b86538a174e49c16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88d2c1471320434e946103ab794deae1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-385a32ca5552>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m### TODO: train and evaluate the model with the functions and data above ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresult_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXLF_train_dloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXLF_val_dloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-b5fbeac98d5e>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(number_of_epochs, model, train_loader, val_loader, min_loss, lr)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mloss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcur_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcur_loss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-a390b342d6aa>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mflattened_expected_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpected_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# flattened_batch_mask = batch_mask.reshape(-1).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mflattened_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_expected_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-312bd1e7d19a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_vector)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;31m# predicted_vector=(batch_size, row length, output_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \t\tpredicted_vector = predicted_vector.reshape((original_shape[0],\n\u001b[0m\u001b[1;32m     76\u001b[0m                                                  original_shape[1], -1))\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 367, -1]' is invalid for input of size 64"
          ]
        }
      ],
      "source": [
        "# Setting seed ***DO NOT MODIFY***\n",
        "torch.manual_seed(123)\n",
        "\n",
        "### TODO: add code for creating model (check updated header for FFNN)\n",
        "model = FFNN(367, 150, 2)\n",
        "\n",
        "### Initialize model weights\n",
        "model.apply(weight_init)\n",
        "\n",
        "### TODO: train and evaluate the model with the functions and data above ###\n",
        "result_model = train_and_evaluate(4, model.cuda(), XLF_train_dloader, XLF_val_dloader, 0.2, 0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aob-sNRxMVA3"
      },
      "outputs": [],
      "source": [
        "# TODO : add a single line code that saves your model in order to prevent re-training the model for later use.\n",
        "\n",
        "model.save_model(\"ffnn_kaggle.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P01jb2711YO-"
      },
      "outputs": [],
      "source": [
        "# Example of how to load\n",
        "ffnn = FFNN(300, 150, 9, 12414)\n",
        "ffnn.load_model(\"ffnn_kaggle.pth\")\n",
        "ffnn = ffnn.to(get_device())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single hidden Layer RNN**"
      ],
      "metadata": {
        "id": "B7QbF2FVdSvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#########################             CHANGED             ######################\n",
        "################################################################################\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, vocab_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, max_norm=True)\n",
        "        self.loss_class_weights = torch.tensor([0.5, 1, 1, 1, 1, 1, 1, 1, 1], \n",
        "                                               dtype=torch.float)\n",
        "        ### TODO : Initialize dimensions of all layers.\n",
        "        ### TODO : Initialize three linear layers:\n",
        "              # 1. An input layer\n",
        "        self.input_layer=nn.Linear(embedding_dim, hidden_dim)\n",
        "              # 2. A hidden layer\n",
        "        self.hidden_layer=nn.Linear(hidden_dim,hidden_dim)\n",
        "              # 3. An output layer\n",
        "        self.output_layer=nn.Linear(hidden_dim,output_dim)\n",
        "        ### TODO : Initialize the activation function.\n",
        "        self.relu=nn.ReLU()\n",
        "        ### TODO : Initialize softmax and loss functions.\n",
        "        self.lsmax=nn.LogSoftmax(dim = -1)\n",
        "        self.loss=nn.CrossEntropyLoss()\n",
        "\n",
        "        self.h_layer=torch.zeros(1, hidden_dim,dtype=torch.float, device = torch.device(\"cuda:0\"))\n",
        "\n",
        "    def compute_Loss(self, predicted_vector, gold_label, masks):\n",
        "        return self.loss(predicted_vector[masks], gold_label[masks])\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        ### TODO : Write the forward function such that it processes the sentences incrementally. \n",
        "        ### TODO : Return output of the softmax across all time steps\n",
        "\n",
        "        original_shape = inputs.shape\n",
        "        # not sure about this\n",
        "        h_i = torch.zeros_like(self.h_layer)\n",
        "        y = torch.Tensor([]).to(get_device())\n",
        "        # t is time_step\n",
        "        for t in range(max_len):\n",
        "          embeddings = self.embedding(inputs[:, t])\n",
        "          h_i =self.relu(self.hidden_layer(h_i) + self.input_layer(embeddings))\n",
        "          y_i = self.lsmax(self.output_layer(h_i))\n",
        "          shape_y_i = y_i.shape\n",
        "          y_i = y_i.reshape((-1, shape_y_i[0], shape_y_i[1]))\n",
        "          # print(y_i.shape)\n",
        "          y = torch.cat((y, y_i), -1)\n",
        "          \n",
        "\n",
        "        output = y.reshape((original_shape[0],\n",
        "                                                 original_shape[1], -1))\n",
        "        return output\n",
        "\n",
        "    def load_model(self, save_path):\n",
        "        self.load_state_dict(torch.load(save_path))\n",
        "\n",
        "    def save_model(self, save_path):\n",
        "        torch.save(self.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "myBb48Kmfs0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: add code for creating model (check updated header for RNN)\n",
        "rnn = RNN(150, 100, 9, 12414)\n",
        "\n",
        "### Initialize model weights\n",
        "rnn.apply(weight_init)\n",
        "\n",
        "### TODO: train and evaluate the model with the functions and data above ###\n",
        "\n",
        "result_model = train_and_evaluate(6, rnn.cuda(), train_loader, val_loader, 0.05, 0.001)\n",
        "\n",
        "# print(\"I'm not completed yet!\")"
      ],
      "metadata": {
        "id": "wQxtQ66Kf0oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.save_model('rnn_kaggle.pth')\n",
        "rnn.load_model('rnn_kaggle.pth')\n",
        "rnn = rnn.to(get_device())"
      ],
      "metadata": {
        "id": "WSPTGS2zf-Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple hidden layer RNN**"
      ],
      "metadata": {
        "id": "vJVlaX6mtef0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN2(nn.Module):\n",
        "    ### TODO : Modify __init__ header ###\n",
        "    # sl: I think the _init_ header is already initialized, so just left it as it is \n",
        "    ### TODO : Initialize n hidden linear layers in your __init__ ###\n",
        "    # sl: modified the h_layer attribute to be a list of hidden layers instead of a single layer\n",
        "    ### TODO : Modify your forward header ###\n",
        "    # sl: I think the header is already modified when given, not so sure what other arguments we will need\n",
        "    ### TODO : Modify your forward function to: ###\n",
        "        # 1. Pass the data through each hidden layer #\n",
        "        # 2. Save the activation of each layer at each timestep when training=FALSE #\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, vocab_size, hidden_layers = 1): \n",
        "        super(RNN2, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, max_norm=True)\n",
        "        self.loss_class_weights = torch.tensor([0.5, 1, 1, 1, 1, 1, 1, 1, 1], \n",
        "                                               dtype=torch.float)\n",
        "              # 1. An input layer\n",
        "        self.input_layer=nn.Linear(embedding_dim, hidden_dim)\n",
        "              # 2. hidden_layers hidden layer\n",
        "        self.hidden_layer=nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(hidden_layers)])\n",
        "              # 3. An output layer\n",
        "        self.output_layer=nn.Linear(hidden_dim,output_dim)\n",
        "        ### TODO : Initialize the activation function.\n",
        "        self.relu=nn.ReLU()\n",
        "        ### TODO : Initialize softmax and loss functions.\n",
        "        self.lsmax=nn.LogSoftmax(dim = 1)\n",
        "        self.loss=nn.CrossEntropyLoss()\n",
        "        ### sl: initiate a list to save the activations according to post #524\n",
        "        self.save_act = []\n",
        "        self.hidden_dim = hidden_dim\n",
        "        ### 10/25\n",
        "        self.hid2hid = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(hidden_layers-1)])\n",
        "\n",
        "    def compute_Loss(self, predicted_vector, gold_label, masks):\n",
        "        return self.loss(predicted_vector[masks], gold_label[masks])\n",
        "\n",
        "    def forward(self, inputs, training = True):\n",
        "        ### TODO : Write the forward function such that it processes the sentences incrementally. \n",
        "        ### TODO : Return output of the softmax across all time steps\n",
        "        ### sl: modified 10/22: nn does NOT step given a python list. It only optimize\n",
        "        \n",
        "        h_i = [torch.zeros(1, self.hidden_dim,dtype=torch.float, device = torch.device(\"cuda:0\")) for _ in range(len(self.hidden_layer))]\n",
        "        output = torch.Tensor([]).to(get_device())\n",
        "        original_shape = inputs.shape\n",
        "        # go through each token\n",
        "        for t in range(max_len):\n",
        "          # copied from FFNN\n",
        "          embeddings = self.embedding(inputs[:, t])\n",
        "          for count, hidden in enumerate(self.hidden_layer):\n",
        "            if count == 0: \n",
        "              h_i[count] = self.relu(hidden(h_i[count]) + self.input_layer(embeddings))\n",
        "            else:\n",
        "              h_i[count] = self.relu(hidden(h_i[count]) + self.hid2hid[count - 1](h_i[count - 1]))\n",
        "            # if we are testing, we should save the activation results, which is - \n",
        "            if training == False:\n",
        "              self.save_act.append(h_i[count])\n",
        "          # end for loop\n",
        "          output_i = self.lsmax(self.output_layer(h_i[-1]))\n",
        "          self.save_act.append(output_i)\n",
        "          shape_output_i = output_i.shape\n",
        "          output_i = output_i.reshape((-1, shape_output_i[0], shape_output_i[1]))\n",
        "          output = torch.cat((output, output_i), -1)\n",
        "          \n",
        "        output = output.reshape((original_shape[0], original_shape[1], -1))\n",
        "        return output\n",
        "\n",
        "\n",
        "    def load_model(self, save_path):\n",
        "        self.load_state_dict(torch.load(save_path))\n",
        "\n",
        "    def save_model(self, save_path):\n",
        "        torch.save(self.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "8SMVOO0UgJlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO : Train and evaluate your RNN2 ###\n",
        "rnn_2 = RNN2(150, 192, 9, 12414, 3)\n",
        "\n",
        "### Initialize model weights\n",
        "rnn_2.apply(weight_init)\n",
        "\n",
        "### TODO: train and evaluate the model with the functions and data above ###\n",
        "\n",
        "result_model = train_and_evaluate(2, rnn_2.cuda(), train_loader, val_loader, 0.2, 0.001)\n",
        "\n",
        "# print(\"I'm not completed yet!\")"
      ],
      "metadata": {
        "id": "5bvzv8FegOhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_2.save_model('rnn_2_kaggle.pth')\n",
        "rnn_2 = RNN2(150, 192, 9, 12414, 3)\n",
        "rnn_2.load_model('rnn_2_kaggle.pth')\n",
        "rnn_2 = rnn_2.to(get_device())"
      ],
      "metadata": {
        "id": "xwRO1FTVgRMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**create submission**"
      ],
      "metadata": {
        "id": "pJlT6p4FgdjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from pyparsing.helpers import TokenConverter\n",
        "### TODO : pass the processed test data through the model ###\n",
        "\n",
        "with torch.no_grad():\n",
        "  # print(\"I'm not completed yet!\")\n",
        "  ffnn.eval()\n",
        "  count = 0\n",
        "  flattened_predicted_all = torch.Tensor([]).to(get_device())\n",
        "  for (input_batch, expected_out, batch_mask) in tqdm(test_loader, leave=False, desc=\"Validation Batches\"):\n",
        "    # next line commented out since there is no expected output\n",
        "    # flattened_expected_out = expected_out.reshape(-1).to(device)\n",
        "    flattened_batch_mask = batch_mask.reshape(-1).to(device)\n",
        "    output = rnn(input_batch.to(get_device())).to(get_device())\n",
        "    # next line seems not involved in the outputs so commented out\n",
        "    # flattened_output = output.reshape(-1, output.shape[-1])\n",
        "    _, predicted = torch.max(output, -1)\n",
        "    flattened_predicted = predicted.reshape(-1)\n",
        "    flattened_predicted_all = torch.concat((flattened_predicted_all, flattened_predicted))\n",
        "  # mask\n",
        "  flattened_mask = list(itertools.chain.from_iterable(processed_test['mask']))\n",
        "  # count is the index, predicted is the prediction for each token\n",
        "  real_predicted = torch.Tensor([])\n",
        "  for count, predicted in enumerate(flattened_predicted_all):\n",
        "    if flattened_mask[count] == 1:\n",
        "      predicted = torch.Tensor([predicted])\n",
        "      real_predicted = torch.concat((real_predicted, predicted))\n",
        "  real_predicted = real_predicted.tolist()\n"
      ],
      "metadata": {
        "id": "ZUc9Z8ECgdHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO : extract labels and indices for model predictions of named entities ###\n",
        "\n",
        "# Done\n",
        "indices = list(chain.from_iterable(test['index']))\n",
        "num2tag = {y: x for x, y in category_map.items()}\n",
        "res = []\n",
        "for num in real_predicted:\n",
        "  res.append(num2tag[num])"
      ],
      "metadata": {
        "id": "WXt7ZsGRguCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHuT-5VENZIN"
      },
      "outputs": [],
      "source": [
        "def format_output_labels(token_labels, token_indices):\n",
        "    \"\"\"\n",
        "    Returns a dictionary that has the labels (LOC, ORG, MISC or PER) as the keys, \n",
        "    with the associated value being the list of entities predicted to be of that key label. \n",
        "    Each entity is specified by its starting and ending position indicated in [token_indices].\n",
        "\n",
        "    Eg. if [token_labels] = [\"B-ORG\", \"I-ORG\", \"O\", \"O\", \"B-ORG\"]\n",
        "           [token_indices] = [15, 16, 17, 18, 19]\n",
        "        then dictionary returned is \n",
        "        {'LOC': [], 'MISC': [], 'ORG': [(15, 16), (19, 19)], 'PER': []}\n",
        "\n",
        "    :parameter token_labels: A list of token labels (eg. B-PER, I-PER, B-LOC, I-LOC, B-ORG, I-ORG, B-MISC, OR I-MISC).\n",
        "    :type token_labels: List[String]\n",
        "    :parameter token_indices: A list of token indices (taken from the dataset) \n",
        "                              corresponding to the labels in [token_labels].\n",
        "    :type token_indices: List[int]\n",
        "    \"\"\"\n",
        "    label_dict = {\"LOC\":[], \"MISC\":[], \"ORG\":[], \"PER\":[]}\n",
        "    prev_label = 'O'\n",
        "    start = token_indices[0]\n",
        "    for idx, label in enumerate(token_labels):\n",
        "      curr_label = label.split('-')[-1]\n",
        "      if label.startswith('B-') or curr_label != prev_label:\n",
        "        if prev_label != 'O':\n",
        "          label_dict[prev_label].append((start, token_indices[idx-1]))\n",
        "        if curr_label != 'O':\n",
        "          start = token_indices[idx]\n",
        "        else:\n",
        "          start = None\n",
        "      \n",
        "      prev_label = curr_label\n",
        "\n",
        "    if start is not None and prev_label != 'O':\n",
        "      label_dict[prev_label].append((start, token_indices[idx]))\n",
        "    return label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-XrcS8Z0BSk"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def create_submission(output_filepath, token_labels, token_inds):\n",
        "    \"\"\"\n",
        "    :parameter output_filepath: The full path (including file name) of the output file, \n",
        "                                with extension .csv\n",
        "    :type output_filepath: [String]\n",
        "    :parameter token_labels: A list of token labels (eg. PER, LOC, ORG or MISC).\n",
        "    :type token_labels: List[String]\n",
        "    :parameter token_indices: A list of token indices (taken from the dataset) \n",
        "                              corresponding to the labels in [token_labels].\n",
        "    :type token_indices: List[int]\n",
        "    \"\"\"\n",
        "    label_dict = format_output_labels(token_labels, token_inds)\n",
        "    with open(output_filepath, mode='w') as csv_file:\n",
        "        fieldnames = ['Id', 'Predicted']\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for key in label_dict:\n",
        "            p_string = \" \".join([str(start)+\"-\"+str(end) for start,end in label_dict[key]])\n",
        "            writer.writerow({'Id': key, 'Predicted': p_string})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_submission('drive/MyDrive/Colab Notebooks/rnn_kaggle.csv', res, indices)"
      ],
      "metadata": {
        "id": "TCmEcvWK05Yx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}